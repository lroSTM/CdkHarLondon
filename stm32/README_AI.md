---
pagetitle: Release Notes for Sensing and Audio Getting Start Package
lang: en
header-includes: <link rel="icon" type="image/x-icon" href="_htmresc/favicon.png" />
---

# __Sensing and Audio Getting Start Package__

This project provides an STM32 Microcontroler embedded real time environement to execute [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html) generated model targetting sensing and audio applications

## __Keywords__

Getting Start, Model Zoo, Sensing, X-CUBE-AI

## __Hardware and Software environment__

This example runs on [B-U585I-IOT02A](https://www.st.com/en/evaluation-tools/b-u585i-iot02a.html)

### __STM32CubeIDE tool installation__

The STM32CubeIDE tool is required to manage an STM32 AI C-project. It allows to install in a simple way, the requested tools to compile, build and flash a firmware on a STM32 development board.

Download [STM32CubeIDE](https://www.st.com/content/st_com/en/products/development-tools/software-development-tools/stm32-software-development-tools/stm32-ides/stm32cubeide.html), extract the package and execute the installer.

### __X-CUBE-AI tool installation__

[X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html) is an STM32Cube Expansion Package, which is part of the STM32Cube.AI ecosystem. It extends STM32CubeMX capabilities with automatic conversion of pretrained artificial intelligence algorithms, including neural network and classical machine learning models. It integrates also a generated optimized library into the user's project.

This software is tested with [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html) `v8.1.0`. It is advised that the user uses the same version to avoid any potential compatibility issues.

The pack can be installed through [STM32CubeMX](https://www.st.com/content/st_com/en/products/development-tools/software-development-tools/stm32-software-development-tools/stm32-configurators-and-code-generators/stm32cubemx.html) through the  *STM32CubeExpansion* pack mechanism.

### __Installation of the X-CUBE-AI runtime__

Please copy

```bash
<X_CUBE_AI-directory-path>
  \- Middlewares/ST/AI/Inc/*.h
```

into the middleware project directory `'<install-dir>/Middleware/STM32_AI_Library/Inc'`

and

```bash
<X_CUBE_AI-directory-path>
  \- Middlewares/ST/AI/Lib/NetworkRuntime810_CM33_GCC.a
```

into the middleware project directory `'<install-dir>/Middleware/STM32_AI_Library/Lib'`

### __Generation and Installation of the X-CUBE-AI model__

This package does not provides the AI model generated by [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html).
The user needs to generate the AI model either using the *GUI* (*G*raphical *U*ser *I*nterface) or the *CLI* (*C*ommand *L*ine *I*nterface).

The package does not support multiple network, hence please make sure to generate a unique AI network with its default name *network*:

With the *GUI*

![single network configuration](_htmresc/XcubeAisingleNetwork.png)

With the *CLI*, just do *not* use the option ```-n/--name```

After generating the network, please copy the resulting following files:

```bash
<output-directory-path>
  \- App/network*
```

into the project directory `'<install-dir>/Projects/Common/X-CUBE-AI/App'`

### __Configuration__

#### __HAR example__

The user has the possibility to override the default configuration by altering the user configuration header file, `'<install-dir>/Projects/Common/dpu/ai_model_config.h'`.

In this file, you first can describe the number and the nature of the model output:

```C
#define CTRL_X_CUBE_AI_MODE_NB_OUTPUT          (1U) /* or (2U)*/
#define CTRL_X_CUBE_AI_MODE_OUTPUT_1           (CTRL_AI_CLASS_DISTRIBUTION)
```

This version supports one or two output, and each output can be:

```C
#define CTRL_AI_CLASS_DISTRIBUTION (1U)
#define CTRL_AI_CLASS_IDX          (2U)
```

Then you describe the class indexes and their labels in this way:

```C
#define CTRL_X_CUBE_AI_MODE_CLASS_NUMBER       (4U)
#define CTRL_X_CUBE_AI_MODE_CLASS_LIST         {"Jogging","Stationary","Stairs","Walking"}
```

These parameters need to be consistent with the model topology that will be executed

The rest of the model details will be embedded in the `.c` and `.h` files generated by the tool [X-CUBE-AI](https://www.st.com/en/embedded-software/x-cube-ai.html).

Now you can choose to apply an available pre-processing from

```C
typedef enum {
CTRL_AI_GRAV_ROT_SUPPR,
CTRL_AI_GRAV_ROT,
CTRL_AI_PREPROC,
CTRL_AI_SPECTROGRAM_MEL,
CTRL_AI_SPECTROGRAM_LOG_MEL,
CTRL_AI_SPECTROGRAM_MFCC,
CTRL_AI_SCALING,
CTRL_AI_BYPASS
}Ctrl_preproc_t;
```

by defining, for gravity removal as an example:

```C
#define CTRL_X_CUBE_AI_PREPROC                 (CTRL_AI_GRAV_ROT_SUPPR)
```

You will now describe the sensor that will connect to the AI processing chain:

```C
#define CTRL_X_CUBE_AI_SENSOR_TYPE             (COM_TYPE_ACC)
#define CTRL_X_CUBE_AI_SENSOR_ODR              (26.0F)
#define CTRL_X_CUBE_AI_SENSOR_FS               (4.0F)
```

Today , 3D accelerometer (`COM_TYPE_ACC`) and microphone (`COM_TYPE_MIC`) types are available,  you can vary the *F*ull *S*cale (*FS*) parameter given in G and the *O*utput *D*ata *R*ate (*ODR*).

You can find Herebelow a typical configuration for HAR Deep Neural Network:

```C
#define CTRL_X_CUBE_AI_MODE_NB_OUTPUT          (1U)
#define CTRL_X_CUBE_AI_MODE_OUTPUT_1           CTRL_AI_CLASS_DISTRIBUTION
#define CTRL_X_CUBE_AI_MODE_CLASS_NUMBER       (4U)
#define CTRL_X_CUBE_AI_MODE_CLASS_LIST         {"Jogging","Stationary","Stairs","Walking"}
#define CTRL_X_CUBE_AI_SENSOR_TYPE             (COM_TYPE_ACC)
#define CTRL_X_CUBE_AI_SENSOR_ODR              (26.0F)
#define CTRL_X_CUBE_AI_SENSOR_FS               (4.0F)
#define CTRL_X_CUBE_AI_PREPROC                 (CTRL_AI_GRAV_ROT_SUPPR)
```

### __Execution__

The package includes a project executing a controller task that is configurable (as described above) by user through the following header file `'<install-dir>/Projects/Common/dpu/ai_model_config.h'`

The application itself is implemented in :

```bash
<getting-start-install-dir>
  \- /Projects/Common/dpu/*
```

During execution phase the AI model is first loaded and the hardware is set up.

On initialisation, the application loads and checks `X-CUBE-AI` model:

* Api version == `1.2.0` ( `X-CUBE-AI` `7.3.0` & `8.1.0` )
* Input buffers number == `1`
* Outputs buffer number must be less or equal than 2
* Input buffers type : `AI_BUFFER_FMT_TYPE_FLOAT` or `AI_BUFFER_FMT_TYPE_Q` (signed 8 bits)
* Input buffers size is within boundaries (batch < `1`, height < `100`, width <`100`, channels <`100`)
* Output buffers type : `AI_BUFFER_FMT_TYPE_FLOAT`
* Ouput buffers size is within boundaries (batch < `1`, height < `100`, width <`100`, channels <`100`)

A sensor among the available ones is configured.

When data buffer is ready

* If sensor type is accelerometer, calls built-in pre-processing function
* Calls `X-CUBE-AI` model

## __History__

### __V0.1 HAR Initial version__

* Included  HAR model
* Limited to CubeIDE / arm gcc toolchain
